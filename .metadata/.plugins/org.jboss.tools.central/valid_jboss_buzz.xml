<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title type="html">Keycloak 15.0.1 released</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/sciVkF5Nfsc/keycloak-1501-released.html" /><author><name /></author><id>https://www.keycloak.org//2021/08/keycloak-1501-released.html</id><updated>2021-08-07T00:00:00Z</updated><content type="html">To download the release go to . HIGHLIGHTS This release contains some important bug fixes. In addition, We would like to thank to for his contributions to the FAPI related functionalities such as JARM support and improvements in CIBA. ALL RESOLVED ISSUES The full list of resolved issues are available in UPGRADING Before you upgrade remember to backup your database and check the for anything that may have changed.&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/sciVkF5Nfsc" height="1" width="1" alt=""/&gt;</content><dc:creator /><feedburner:origLink>https://www.keycloak.org//2021/08/keycloak-1501-released.html</feedburner:origLink></entry><entry><title type="html">Event Driven Decisioning with AMQ Streams and Kogito</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/8Mn0N_VOwgQ/event-driven-decisioning-with-amq-streams-and-kogito.html" /><author><name>Sadhana Nandakumar</name></author><id>https://blog.kie.org/2021/08/event-driven-decisioning-with-amq-streams-and-kogito.html</id><updated>2021-08-06T16:26:21Z</updated><content type="html">Kogito is a cloud-native business automation framework for building intelligent business applications. The project is based on battle-tested runtime components, and it allows the development of both business processes and rules as cloud-native applications for orchestrating distributed microservices and container-native applications. Kogito takes advantage of the many benefits of the container-native platforms as it was designed from the ground up for those platforms. Real-time decisioning is a powerful concept and has a lot of relevant use cases in the real world. Some common examples are Real Time Fraud detection and Personalized digital banking.  Kogito supports a methodology to allow for seamless integration for Kafka to create such a system. In this article we will take a look at how you can integrate Kogito decisions with Red Hat AMQ Streams on OpenShift. For the purpose of this article, let us consider a simple real time transaction monitoring system. In an earlier article, I had written about how to create a complex model that can identify Fraud or AML activity.  Let us deploy this example using Kogito and integrate this with AMQ Streams. We will first create a new namespace on OpenShift kogito-event-driven-decisions. STEP 1: DEPLOY THE AMQ STREAMS OPERATOR The Operator Hub is a collection of Operators from the Kubernetes community and Red Hat partners, curated by Red Hat. We will install the AMQ Streams operator. Now that the operator is installed, we can now create a simple 3 node Kafka cluster. For this click on the Kafka tab and click on the Create Kafka button. We will accept the defaults and create the Kafka cluster. STEP 2: KOGITO BUSINESS DECISIONS As a first step, let’s head over to . We will create a starter project with Kogito – DMN capabilities. Download the application. We will now add two more dependencies, so that we can connect with the kafka broker. &lt;dependency&gt;  &lt;groupId&gt;org.kie.kogito&lt;/groupId&gt;  &lt;artifactId&gt;kogito-event-driven-decisions-quarkus-addon&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt;  &lt;groupId&gt;io.quarkus&lt;/groupId&gt;  &lt;artifactId&gt;quarkus-smallrye-reactive-messaging-kafka&lt;/artifactId&gt; &lt;/dependency&gt; Now we will add the to the project structure. As you might recollect, we created a DMN called TransactionMonitoringDMN which included the logic from the FraudAlert model and the AMLAlert model. We will add all three of those DMNs to the kogito project. We will now define some configuration information that will allow the Kogito application to connect to Kafka. Open the file src/main/resources/applications.properties and add the following configuration: mp.messaging.incoming.kogito_incoming_stream.group.id=transaction-monitoringmp.messaging.incoming.kogito_incoming_stream.connector=smallrye-kafkamp.messaging.incoming.kogito_incoming_stream.topic=transaction-decision-requestmp.messaging.incoming.kogito_incoming_stream.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer mp.messaging.outgoing.kogito_outgoing_stream.group.id=transaction-monitoringmp.messaging.outgoing.kogito_outgoing_stream.connector=smallrye-kafkamp.messaging.outgoing.kogito_outgoing_stream.topic=transaction-decision-responsemp.messaging.outgoing.kogito_outgoing_stream.value.serializer=org.apache.kafka.common.serialization.StringSerializerkafka.bootstrap.servers=my-cluster-kafka-brokers:9092 Notice that we have defined the bootstrap URL for the Kafka cluster and the topic properties for the incoming and outgoing topics. We will now check in the changes to a version control system like . Step 3: Deploy the Kogito Application on Openshift Let us now install the Kogito Operator on OpenShift. For this search for Kogito, choose the RHPAM Kogito operator and proceed. We will install the operator in the same namespace (kogito-event-driven-decisions). Now click on the tab Kogito Build, and click on Create Kogito Build. We will edit the name as transaction-monitor, and define the Git source from which it can build the kogito application. We will accept all the other defaults and submit. The Kogito Build can also be defined using a yaml. Check out the definition . This should kick start a build in the namespace as below. We will define a Kogito Runtime that will help deploy the changes. For this go back to the operator and click on tab as below We will create a runtime, name it as transaction-monitor and submit. The Kogito Runtime can also be defined using a yaml. Check out the definition . STEP 4: TESTING THE DMN DECISIONS USING KAFKA Let us now produce an event on the transaction-decision-request topic. For this we will use a simple python utility. This application generates events every few minutes. While logged in to the OpenShift environment via command line, we can use the following command: oc new-app centos/python-36-centos7~https://github.com/snandakumar87/transaction-monitoring-emitter -e KAFKA_BROKERS=my-cluster-kafka-brokers:9092 -e KAFKA_TOPIC=transaction-decision-request -e RATE=1 --name=emitter The request sent to kogito should be in a format. This format provides a specification for defining event messages in a common way. A sample request message to the request topic would look like this: { "specversion": "1.0", "id": "a89b61a2-5644-487a-8a86-144855c5dce8", "source": "SomeEventSource", "type": "DecisionRequest", "subject": "TheSubject", "kogitodmnmodelname": "TransactionMonitoringDMN", "kogitodmnmodelnamespace": "https://kiegroup.org/dmn/_EED47FB5-8A7C-44F3-A786-563FD2DAF015", "data": { "Transaction": { "transactionAmount": 9500, "transactionCountry": "US", "merchantType": "MERCH336", "transactionType": "Web", "transactionId": 1626891159443, "paymentMode": "savings" }, "Customer": { "averageTransactionAmount": 300, "riskIndex": 1.7, "marriage": false, "jobChange": false, "cityChange": false, "customerId": "CUST898920" } } } Observe how the data section contains the payload details, or the facts, that are needed to be evaluated by the DMN decision. Now that we have defined the emitter, let us install an open source Kafka UI () to check out the decision response. For deploying this, we can use the following command. oc apply -f https://raw.githubusercontent.com/snandakumar87/transaction-monitoring-dmn-kogito/master/ocp-deploy/kafdrop.yml The yaml definition for installing Kafdrop can be found . Once the deployment is completed, we can access the route definition to open up the kafka UI. From the Kafdrop UI, choose the response topic. Click on View Messages, you should see the response of the DMN decision as below. Notice how the response is also in the CloudEvents format. The data section contains the evaluated response of the decision execution. SUMMARY As we called out earlier, Event Driven Decisioning is a powerful concept, and by externalizing the rules that drive the event behavior, we are able to make the overall process more transparent and agile. Kogito provides a simple and a robust way to implement such an architecture. Click here to learn more about . The post appeared first on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/8Mn0N_VOwgQ" height="1" width="1" alt=""/&gt;</content><dc:creator>Sadhana Nandakumar</dc:creator><feedburner:origLink>https://blog.kie.org/2021/08/event-driven-decisioning-with-amq-streams-and-kogito.html</feedburner:origLink></entry><entry><title>Porting your code to C++17 with GCC 11</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/4PAS56DtvZw/porting-your-code-c17-gcc-11" /><author><name>Marek Polacek</name></author><id>d416f85f-62bf-4e9d-9937-45c7be400af8</id><updated>2021-08-06T07:00:00Z</updated><published>2021-08-06T07:00:00Z</published><summary type="html">&lt;p&gt;The &lt;a href="https://gcc.gnu.org/"&gt;GNU Compiler Collection&lt;/a&gt; (GCC), which is the standard compiler on &lt;a href="https://developers.redhat.com/topics/linux"&gt;GNU/Linux&lt;/a&gt; distributions such as &lt;a href="https://getfedora.org/"&gt;Fedora&lt;/a&gt; and &lt;a href="https://developers.redhat.com/products/rhel"&gt;Red Hat Enterprise Linux&lt;/a&gt;, &lt;a href="https://gcc.gnu.org/gcc-11/"&gt;moved from version 14 to version 17 of C++&lt;/a&gt; in April 2021. Thus, the &lt;code&gt;-std=gnu++17&lt;/code&gt; command-line option is now used by default.&lt;/p&gt; &lt;p&gt;&lt;a href="https://gcc.gnu.org/projects/cxx-status.html#cxx17"&gt;C++17 brings a host of new features&lt;/a&gt;, but also deprecates, removes, or changes the semantics of certain constructs. This article looks at some of the issues you might face when switching to GCC 11. Remember that it is always possible to use the previous version of C++ by specifying the &lt;code&gt;-std=gnu++14&lt;/code&gt; option. Moreover, this article deals only with the core language; we won't discuss deprecated or removed features in the standard C++ library (such as &lt;code&gt;auto_ptr&lt;/code&gt;). For a broader overview, I encourage visiting the paper &lt;a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0636r3.html"&gt;Changes between C++14 and C++17&lt;/a&gt;. For more information regarding switching to using GCC 11, please see our upstream document, &lt;a href="https://gcc.gnu.org/gcc-11/porting_to.html"&gt;Porting to GCC 11&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Removed in C++17&lt;/h2&gt; &lt;p&gt;We'll start with what has been removed in C++17: Trigraphs, the &lt;code&gt;register&lt;/code&gt; keyword, and increments on the &lt;code&gt;bool&lt;/code&gt; type.&lt;/p&gt; &lt;h3&gt;Trigraphs&lt;/h3&gt; &lt;p&gt;In C++, a &lt;em&gt;trigraph&lt;/em&gt; is a sequence of three characters starting with &lt;code&gt;??&lt;/code&gt; that can express single punctuation characters. For instance, &lt;code&gt;\&lt;/code&gt; can be written as &lt;code&gt;??/&lt;/code&gt;. The reason for this is historical: C and C++ use special characters such as &lt;code&gt;[&lt;/code&gt; and &lt;code&gt;]&lt;/code&gt; that are not defined in the ISO 646 character set (and so some keyboards are missing these keys). The positions of these characters in the ISO table might be occupied by different characters in national ISO 646 characters sets, such as &lt;code&gt;¥&lt;/code&gt; in place of &lt;code&gt;\&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Trigraphs were meant to allow programmers to enter the characters that weren't on the keyboard. But in practice, trigraphs are likely to be used only by accident, so they were &lt;a href="https://wg21.link/n4086"&gt;removed in C++17&lt;/a&gt;. The removal allows you to play "cute" games like the following test. Can you see why it works?&lt;/p&gt; &lt;pre&gt; &lt;code class="language-cpp"&gt;bool cxx_with_trigraphs_p () { // Are we compiling in C++17??/ return false; return true; }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;If for some reason you still need to use trigraphs in C++17 (indeed, there are code bases that &lt;a href="https://wg21.link/n2910"&gt;still use trigraphs&lt;/a&gt;), GCC offers the &lt;code&gt;-trigraphs&lt;/code&gt; command-line option.&lt;/p&gt; &lt;h3&gt;The register keyword&lt;/h3&gt; &lt;p&gt;The &lt;code&gt;register&lt;/code&gt; keyword was deprecated in C++11 with &lt;a href="https://wg21.link/cwg809"&gt;CWG 809&lt;/a&gt; because it had no practical effect. C++17 cleaned this up further by &lt;a href="https://wg21.link/p0001r1"&gt;removing the keyword&lt;/a&gt; completely (though it remains reserved for future use). Therefore, code such as the following causes GCC 11 to warn by default, and to issue an error when the &lt;code&gt;-pedantic-errors&lt;/code&gt; option is used:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-cpp"&gt;void f () { register int i = 42; // warning: ISO C++17 does not allow 'register' storage class specifier int register; // error }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;In C++14, you can instruct the compiler to warn using &lt;code&gt;-Wregister&lt;/code&gt;, which ought to help you migrate code to C++17. Note that GCC still accepts the GNU &lt;a href="https://gcc.gnu.org/onlinedocs/gcc/Global-Register-Variables.html#Global-Register-Variables"&gt;explicit register variables&lt;/a&gt; extension without warning:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-cpp"&gt;register int g asm ("ebx");&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Increments on the bool type&lt;/h3&gt; &lt;p&gt;In C++, the &lt;code&gt;--&lt;/code&gt; operator has never been supported for objects of type &lt;code&gt;bool&lt;/code&gt;. But &lt;code&gt;++&lt;/code&gt; on a &lt;code&gt;bool&lt;/code&gt; was originally valid, and was deprecated but not removed in C++98. In the spirit of C++17, post-increment and pre-increment are now forbidden, so GCC will give an error for code that uses them:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-cpp"&gt;template&lt;typename T&gt; void f() { bool b = false; b++; // error: use of an operand of type 'bool' in 'operator++' is forbidden in C++17 T t{}; t++; // error: use of an operand of type 'bool' in 'operator++' is forbidden in C++17 } void g() { f&lt;bool&gt;(); }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Instead of &lt;code&gt;++&lt;/code&gt;, simply use &lt;code&gt;b = true&lt;/code&gt; or &lt;code&gt;b |= true&lt;/code&gt; depending on the specific case.&lt;/p&gt; &lt;h2&gt;Exception specification changes&lt;/h2&gt; &lt;p&gt;Keywords related to exceptions have been added to C++ over various versions of the language. C++17 introduces changes to the &lt;code&gt;noexcept&lt;/code&gt; specification while removing dynamic exception specifications.&lt;/p&gt; &lt;h3&gt;Exception specifications are now part of the type system&lt;/h3&gt; &lt;p&gt;C++1 1 added the &lt;code&gt;noexcept&lt;/code&gt; exception specification in &lt;a href="https://wg21.link/n3050"&gt;N3050&lt;/a&gt;. Since C++17, &lt;code&gt;noexcept&lt;/code&gt; has become part of the type. Thus, the following two functions have the same type in C++14, but different types in C++17:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-cpp"&gt;int foo () noexcept; int bar ();&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;However, this doesn't mean that &lt;code&gt;noexcept&lt;/code&gt; is part of a function's signature. Therefore, you cannot overload a function as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-cpp"&gt;int baz(); int baz() noexcept; // error: different exception specifier (even in C++11)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Another consequence is that in C++17, a pointer to a function that could potentially throw cannot be converted to a function that cannot throw:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-cpp"&gt;void (*p)(); void (*q)() noexcept = p; // OK in C++14, error in C++17&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This change also affects template arguments. The following program will not compile in C++17, because the compiler deduces two conflicting types for the template parameter &lt;code&gt;T&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-cpp"&gt;void g1 () noexcept; void g2 (); template&lt;typename T&gt; int foo (T, T); void f() { foo (g1, g2); // error: void (*)() noexcept vs void (*)() }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Interestingly, this change was first discussed more than 20 years ago in &lt;a href="https://wg21.link/cwg92"&gt;CWG 92&lt;/a&gt;, and was finally adopted in &lt;a href="https://wg21.link/p0012"&gt;P0012R1&lt;/a&gt;.&lt;/p&gt; &lt;h3&gt;Removal of dynamic exception specifications&lt;/h3&gt; &lt;p&gt;C++11 deprecated dynamic exception specifications in &lt;a href="https://wg21.link/n3051"&gt;N3051&lt;/a&gt;, and C++17 removed them altogether in &lt;a href="https://wg21.link/p0003"&gt;P0003R5&lt;/a&gt;. The exception is that &lt;code&gt;throw()&lt;/code&gt; continues to work in C++17, and is equivalent to &lt;code&gt;noexcept(true)&lt;/code&gt;, although it has been removed in C++20. Moreover, in C++17, the function &lt;code&gt;std::unexpected&lt;/code&gt; was removed. This function used to be called if a function decorated with &lt;code&gt;throw()&lt;/code&gt; actually did throw an exception. In C++17, &lt;code&gt;std::terminate&lt;/code&gt; is called instead.&lt;/p&gt; &lt;p&gt;C++17 code cannot use dynamic exception specifications and should replace &lt;code&gt;throw()&lt;/code&gt; with &lt;code&gt;noexcept&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;The following example might help to clarify the usage:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-cpp"&gt;void fn1() throw(int); // error in C++17, warning in C++14 void fn2() noexcept; // OK since C++11 void fn3() throw(); // deprecated but no warning in C++17 void fn4() throw() { throw; } // In C++14, calls std::unexpected which calls std::unexpected_handler // (which is std::terminate by default). // In C++17, calls std::terminate directly.&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;New template template-parameter matching&lt;/h2&gt; &lt;p&gt;The C++17 proposal &lt;a href="https://wg21.link/p0522"&gt;P0522R0: Matching of template template-arguments excludes compatible templates&lt;/a&gt;, which fixed &lt;a href="https://wg21.link/cwg150"&gt;DR 150&lt;/a&gt;, was implemented in GCC 7 in the &lt;code&gt;-fnew-ttp-matching&lt;/code&gt; option but was turned off by default. Because GCC 11 defaults to C++17, the new behavior is enabled by default.&lt;/p&gt; &lt;p&gt;In the old behavior, the template template-argument for a template template-parameter must be a template with a parameter list that exactly matches the corresponding parameters in the template parameter's parameter list. The new behavior is less strict, by considering default template arguments of template template-arguments in the match.&lt;/p&gt; &lt;p&gt;This change was problematic for some templates in the standard library. For instance, &lt;code&gt;std::deque&lt;/code&gt; is a template with the following default template argument:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-cpp"&gt;template&lt;typename T, typename Allocator = std::allocator&lt;T&gt;&gt; class deque;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Therefore, the following code works only with the new GCC 11 behavior:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-cpp"&gt;#include &lt;deque&gt; template &lt;template &lt;typename&gt; class&gt; void fn() {} template void fn&lt;std::deque&gt;();&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The workaround is to adjust the declaration so that the parameter expects two type parameters:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-cpp"&gt;#include &lt;deque&gt; template &lt;template &lt;typename, typename&gt; class&gt; void fn() {} template void fn&lt;std::deque&gt;();&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;However, the new behavior can also cause code that worked in the old behavior to stop compiling with an error:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-cpp"&gt;template &lt;int N, int M = N&gt; class A { }; template &lt;int N, int M&gt; void fn(A&lt;N, M&gt;) {} template &lt;int N, template &lt;int&gt; typename T&gt; void fn(T&lt;N&gt;); void g () { A&lt;3&gt; a; fn (a); // ambiguous in C++17 }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The reason is that &lt;code&gt;A&lt;/code&gt; is considered a valid argument for &lt;code&gt;T&lt;/code&gt; in the new behavior. Therefore, both function templates are valid candidates, and because neither is more specialized than the other, the function call to &lt;code&gt;fn&lt;/code&gt; has become ambiguous.&lt;/p&gt; &lt;p&gt;It's possible to revert to the old behavior, even in C++17 mode, by using &lt;code&gt;-fno-new-ttp-matching&lt;/code&gt;.&lt;/p&gt; &lt;h2&gt;Static constexpr and consteval class members implicitly inline&lt;/h2&gt; &lt;p&gt;The C++17 proposal to introduce inline variables (&lt;a href="https://wg21.link/p0386"&gt;P0386R2&lt;/a&gt;) brought the following change into the [dcl.constexpr] section of the specification: "A function or static data member declared with the &lt;code&gt;constexpr&lt;/code&gt; or &lt;code&gt;consteval&lt;/code&gt; specifier is implicitly an inline function or variable."&lt;/p&gt; &lt;p&gt;As a consequence, the member variable &lt;code&gt;A::n&lt;/code&gt; in the following example is a definition in C++17. The declaration labeled &lt;code&gt;#2&lt;/code&gt; in a comment was required in C++14. In C++17, the &lt;code&gt; #2&lt;/code&gt; declaration can be removed:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-cpp"&gt;struct A { static constexpr int n = 5; // #1, definition in C++17, declaration in C++14 }; constexpr int A::n; // #2, definition in C++14, deprecated redeclaration in C++17 auto g() { return &amp;A::n; // ODR-use of A::n -- needs a definition }&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Changes to evaluation order&lt;/h2&gt; &lt;p&gt;C++17 &lt;a href="https://wg21.link/p0145"&gt;P0145R3&lt;/a&gt; clarified the order of evaluation of various expressions. As the proposal states, the following expressions are evaluated in such a way that &lt;code&gt;a&lt;/code&gt; is evaluated before &lt;code&gt;b&lt;/code&gt;:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;code&gt;a.b&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;a-&gt;b&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;a-&gt;*b&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;a (b1, b2, b3)&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;b op= a&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;a[b]&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;a &lt;&lt; b&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;a &gt;&gt; b&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;These rules have caused some changes in the GCC compiler, and certain code might behave differently in C++14 and C++17, as the following test illustrates. It is possible to selectively adjust the compiler behavior using the &lt;code&gt;-fstrong-eval-order={all|some|none}&lt;/code&gt; compile-time option, where &lt;code&gt;all&lt;/code&gt; is the default in C++17 and &lt;code&gt;some&lt;/code&gt; is the default in C++14.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-cpp"&gt;int fn () { int ar[4]{ }; int i = 0; ar[i++] = i; return ar[0]; // returns 0 in C++17, 1 in C++14 } int fn2 () { int x = 2; return x &lt;&lt; (x = 1, 2); // returns 8 in C++17, 4 in C++14 } int fn3 () { int x = 6; return x &gt;&gt; (x = 5, 1); // returns 3 in C++17, 2 in C++14 }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The aforementioned &lt;a href="https://wg21.link/p0145"&gt;P0145R3&lt;/a&gt; paper also defines the evaluation order when some of the affected operands are overloaded and are using the operator syntax: They follow the order prescribed for the built-in operator.&lt;/p&gt; &lt;h2&gt;Guaranteed copy elision&lt;/h2&gt; &lt;p&gt;C++17 requires guaranteed copy elision, meaning that a copy or move constructor call will be elided completely under certain circumstances (such as when the type of the initializer and target are the same), even when the call has side effects. That means that, theoretically, if something relied on a constructor being instantiated, for example, via copying a function parameter, the program could now fail, because the constructor might not be instantiated in C++17.&lt;/p&gt; &lt;p&gt;GCC already performed copy/move elision as an optimization even in C++14 mode, so such failures are unlikely to happen in practice. However, the difference is that in C++17 the compiler will not perform access checking on the elided constructor, so code that didn't compile previously could compile now, as demonstrated by the following snippet:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-cpp"&gt;class A { int i; public: A() : i{42} {} private: A(const A &amp;); }; struct B { A a; B() : a(A()) {} // OK in C++17, error in C++14 };&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Summary&lt;/h2&gt; &lt;p&gt;I hope these notes will be useful for developers migrating to GCC 11. As with every major release, we've added new warnings that might turn up when switching compilers. Should you find a bug in these new warnings, please don't hesitate to open a new problem report as outlined in the &lt;a href="https://gcc.gnu.org/bugs/"&gt;GCC bugs page&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/08/06/porting-your-code-c17-gcc-11" title="Porting your code to C++17 with GCC 11"&gt;Porting your code to C++17 with GCC 11&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/4PAS56DtvZw" height="1" width="1" alt=""/&gt;</summary><dc:creator>Marek Polacek</dc:creator><dc:date>2021-08-06T07:00:00Z</dc:date><feedburner:origLink>https://developers.redhat.com/articles/2021/08/06/porting-your-code-c17-gcc-11</feedburner:origLink></entry><entry><title type="html">How to develop better web widgets with showcase applications</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/xyEi-bfHXX8/how-develop-better-widgets-with-showcase-appl.html" /><author><name>Valentino Pellegrino</name></author><id>https://blog.kie.org/2021/08/how-develop-better-widgets-with-showcase-appl.html</id><updated>2021-08-05T15:05:53Z</updated><content type="html">When I was approaching the new Boxed Expression Editor development, the first challenge I faced was integrating an independent and isolated React component within an existing application. It turned out that defining in a precise manner what is the input and the output of such an editor was a mandatory step to follow. Let’s explore better the concept of a showcase application and how it is possible to build one. In general, instantiating a React component in a separated application leads to a series of benefits discussed below. SHOWCASE APP – STRUCTURE When we talk about showcase applications, we mean a simple React application shipped with the component we are working on (in our case, the BoxedExpressionEditor). In a possible setup, the showcase directory is contained inside the root directory of the component. The wire connecting the showcase with the BoxedExpressionEditor is a link (named lib) pointing to ./../../src (i.e., BoxedExpressionEditor’s source folder). Below, you can find the overall folder structure: On the other side, a different approach could be to publish the BoxedExpressionEditor on an npm registry and to use it as a dependency in a separate showcase application. However, even if it is more formal, that approach leads to an overhead due to publishing and downloading the component every time you need to change it. HOW CAN I LAUNCH MY REACT COMPONENT WITH A SHOWCASE APPLICATION? First, consider that the showcase application can be as simple as you need.  For our example, you need to add two dependencies: react-scripts and react-app-rewired. In the most simple version, the showcase has only two npm scripts: * start: launches the React application (react-app-rewired start). * build: builds a deploy-ready version of the overall application (react-app-rewired build). We will see how to use such artifacts later. In the root source file (typically index.tsx, depending on your project setup), you will import the component by referencing the lib folder: import { BoxedExpressionEditor } from "./lib"; In that way, you can render it in a given DOM node (let’s call it root) with the command: ReactDOM.render(&lt;BoxedExpressionEditor expressionDefinition={expressionDefinition} pmmlParams={pmmlParams} /&gt;, document.getElementById("root")); In the end, you can simply execute the start script for having the showcase application, with your component, up and running! HOW DOES MY REACT COMPONENT RECEIVE INPUT AND PROPAGATE OUTPUT? How the React component communicates with the external world should be well defined, and its design can help figure out integration issues. As every React component, it receives, as input, component properties used for the initial state. The BoxedExpressionEditor, in the example above, expects two parameters: expressionDefinition and pmmlParams: two simple objects. When something inside the component changes and we need to communicate it to the external world (for synchronization purposes, for example), a React component generally triggers a callback (received in the properties) passing its updated state. In this case, the chosen output mechanism is slightly different because we want to ensure that the React component can communicate adequately with another technology (like GWT). Therefore, there is a dedicated JavaScript namespace, for example, called beeApi, containing all functions that the BoxedExpressionEditor will call and it is expecting that someone, in the external world, has defined: //Defining global function that will be available in the Window namespace and used by the BoxedExpressionEditor component window.beeApi = {...//functions...} The showcase application will implement all these functions like the real-world hoster application will do. Thus, all described above is a contract between the React component and whoever will use it. You can enforce this contract by using TypeScript, and start-up checks, as well. QUICKLY SHARE YOUR REACT COMPONENT WITH STAKEHOLDERS While developing a component that will be relevant for many people, you will find out that it is necessary to find a quick way to share the results of your work to get feedback and concerns as soon as possible. In that way, you can apply incremental changes following Agile principles. For sure, it is not possible to ask someone to check out and build locally the showcase application, especially if they are not confident with git or yarn commands. In that scenario, a static deployed website can help. There are several places where you can host a static website. Here we are going to explore two alternatives. It is just a starting point for helping you find the one that fits better with your needs. GITHUB PAGES A simple way to host a static web application is by using the feature. It enables you to build a website from scratch or generate one for your project. To host a React application, you need to: 1. First, install gh-pages as a dev dependency. 2. Create the homepage entry in the package.json file. That entry will be something like http://{username}.github.io/{repository}, where username is the GitHub username and repository is the repository where React application’s codebase is. 3. Add the scripts "predeploy": "yarn build" and "deploy": "gh-pages -d build". Once you run the command yarn deploy, you will create a branch named gh-pages that will host the React application on the homepage reported on the package.json. NETLIFY There are at least a React application to Netlify.  Let me describe the one I prefer that gives me the best control over what I want to deploy: 1. Run the command yarn build to create the build folder. 2. In the deploys section of the Netlify webpage, drag-and-drop the build folder in the corresponding section: After a few seconds, your static application will be available and ready to be shared! WATCH AND EDIT YOUR REACT COMPONENT’S DEFINITION AS IF YOU ALREADY INTEGRATED IT It is very likely that your React component will receive data points representing the initial state and that it will send, in some way, some data back on certain events. Whatever data it will treat, you can find a strategy to represent them in a structured way. For instance, even if the DMN decision models are interchangeable across organizations via an XML representation, you can use, e.g., the JSON representation for instantiating a DMN editor, thanks to the abstraction and layer separation you will build. ADD A SECTION IN THE SHOWCASE APPLICATION FOR WATCHING THE COMPONENT DEFINITION During the development phase, you can link a text area anywhere in your showcase application containing the definition related to the component you are presently observing, just for your convenience. In that way, you can always take a snapshot of your component, for example, for debugging purposes. React offers very flexible mechanisms for sharing the same object between the target component and a textarea. Shared status, with re-rendering on their changes, can be obtained via the useState hook. TYPE THE COMPONENT DEFINITION DIRECTLY IN THE SHOWCASE APPLICATION Imagine you are at the point you were able to reproduce a problematic scenario that requires a few minutes to be built via manual steps. Ok, you can wrap it in your application, mocking the data the component receives as input. Or you can write a dedicated automation test case covering this corner case. Then, you found another complex scenario, and you want to switch between one scenario and another, etc. Why should you not type (or paste) a JSON definition directly into the showcase application that makes the showcase re-render the component contained in it? You can easily do it with React! Other than using the useState hook, you can make your application reactive, on definition text change, using the useEffect hook to on some state change. CONCLUSION Developing complex user interfaces with React has become fast and fulfilling. But, typically, you will not create something that will live alone and need integration.  There are few techniques you can follow to make development easier. For instance, a showcase application can help you to anticipate integration problems or to solve existing ones in three main ways: 1. Show someone how the component will look like in a container, considering responsive constraints, if any. 2. Watch the most updated version of the component definition while you are interacting with it. 3. Pass a custom component definition to make it re-render as you need. Stay tuned for understanding more how our components work under the hoods! The post appeared first on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/xyEi-bfHXX8" height="1" width="1" alt=""/&gt;</content><dc:creator>Valentino Pellegrino</dc:creator><feedburner:origLink>https://blog.kie.org/2021/08/how-develop-better-widgets-with-showcase-appl.html</feedburner:origLink></entry><entry><title type="html">Add data from KIE execution server for authoring dashboards</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/AcKfROLShQU/add-data-from-kie-execution-server-for-authoring-dashboards.html" /><author><name>Manaswini Das</name></author><id>https://blog.kie.org/2021/08/add-data-from-kie-execution-server-for-authoring-dashboards.html</id><updated>2021-08-05T13:12:20Z</updated><content type="html">is a standalone tool that is also integrated into Business Central and is used by the Datasets editor and Content Manager page to facilitate creating dashboards and reporting indicating key performance indicators(KPIs), metrics, and other key data points related to business or specific processes. You can get started by referring to the , if you are a first-time user. Refer to for configuring CSV datasets and for configuring Prometheus datasets for authoring dashboards on DashBuilder. In the , we walked you through the process of adding SQL datasets for authoring dashboards in DashBuilder. When it comes to building dashboards, you can configure the dashboards to consume your own datasets in DashBuilder from a variety of sources like Bean, CSV, SQL, Prometheus, Elastic Search, Kafka, and Execution server. In this post, you will learn how to add and configure data from the KIE execution server for your dashboards. ABOUT KIE EXECUTION SERVER The KIE Execution Server is a standalone, out-of-the-box component that can be used to instantiate and execute rules via interfaces available for REST, JMS, or a Java client-side application. Created as a web deployable WAR file, this engine can be deployed on any web container. Refer to to know more about the KIE execution server. ADD AND CONFIGURE DATA FROM KIE EXECUTION SERVER ON DASHBUILDER There are two ways in which you can add data from the KIE execution server to DashBuilder. USING THE JBPM SERVER server has a full setup and configuration and consists of the capabilities of Business central and KIE Execution server. You can configure your Execution server right here and author dashboards at the same time. 1. Head over to and follow the instructions on the card on the right side to download and run the jBPM server. Go to on a browser. You will see the below screen. Business Central Home page 2. Login using the wbadmin credentials for both username and password fields. Follow the instructions in the following video to add IT orders sample projects. You can also choose to create a project of your own or import a project. Here is a video for your reference. 3. Head over to the to try more examples or switch to another database. Once you have deployed the project and verified it, click on the gear icon on the navbar and select “Datasets”. You can now click on the “New Data Set” button on the top of the “Data Set Explorer” sidebar(this sidebar is responsible for displaying all the datasets you have added and configured to be later consumed by pages and dashboards) or the “new data set” hyperlink on the Data Set authoring Home page. 4. You can now see a familiar “Data Set Creation Wizard” page which lists all the datasets providers. Select “Execution Server”. Data Set Creation Wizard page 5. You will now see the following screen to add data from the KIE execution server. Add a name. In the Server configuration dropdown, select sample-server and select “PROCESS” in the query target dropdown and add the query as shown in the screenshot below. Refer to the Data model for to know more about other tables you can use for querying. Refer to to know more about queries for building KIE server dashboards. Execution server Data Set Editor(Configuration tab) If you are confused about the role of the fields, please hover on the question mark icons beside the fields or the text boxes adjacent to them. Click on Test to preview your dataset. Note: You may get com.google.gwt.core.client.JavaScriptException: (TypeError) : Cannot read property ‘getTimezoneOffset’ of undefined if you try to test a query the second time. After testing the query, drop the dataset and start a new one. 6. You are now on the Preview tab. You can now have a look at the data columns and add filters in the tabs above the dataset. You can also edit the types or delete the columns that you don’t require by unchecking the checkbox beside the columns provided on the left side. If the preview isn’t what you expected, you can switch back to the Configuration tab by clicking on it and make changes. If you are satisfied with the preview, click on the “Next” button. 7. Enter required comments in the Save modal and click on the Save button. Your dataset has been added and configured. You will now be directed back to the Data Set Authoring Home page. You can now see a dataset on the left pane. When you add multiple datasets, you can see the list of all of them on the left pane. Here is a screen recording of the full flow. Add data from KIE execution server You can now click on the Menu dropdown on the navigation bar and select Content Manager to create pages and dashboards. Ensure that the columns are well configured with proper types in the “Data” section of the “Displayer Editor” after dragging the component. USING WILDFLY AND KIE SERVER WAR 1. To get started, you will have to configure the KIE server to run on the WildFly server. For this example, I have used WildFly 19.0.0 . and the to deploy in the WildFly server. Unzip the WildFly zip and open a terminal inside the WildFly unzipped folder(let’s call this WILDFLY_HOME). Copy the WAR file (e.g. kie-server-7.15.0.Final-ee7.war) into the deployments folder of WildFly. You can rename it to “kie-server.war” for your convenience. Start WildFly using the standalone-full.xml profile. Go to “/bin” and run “standalone.sh” using ./standalone.sh -c standalone-full.xml or sudo sh standalone.sh -c standalone-full.xml. You can now find the WildFly server running in localhost:9990 and see the following screen which prompts to add a user. 2. Open another terminal and run ./bin/add-user.sh -a -u kieserver -p password1! -g admin,kie-server . This is how your terminal will look like: Add an ApplicationRealm user This is the command that you can use to add a user to the ApplicationRealm. For the Management realm, open another terminal and run ./bin/add-user.sh and add a ManagementRealm user by selecting option “a” and adding a username and password, followed by adding an “admin” group following the instructions flashing on the terminal. Here is what the terminal should look like after you add a user. Add a ManagementRealm user Note: You have to add a ManagementRealm user to login into WildFly, the ApplicationRealm users are the users you will need to login into the apps deployed in WildFly, like DashBuilder and KIE server in this case. 3. Click on the “Try again” link on the browser and login the same credentials that you configured in the terminal for Management Realm. You will now be able to see the HAL Management Console screen. HAL Management Console 4. Now click on the Start link under Deployments and you can see the KIE server deployment. You can click on the link against “Context Root” in order to access KIE server, you have to go to , now you will be required to enter the username and password that you configured earlier, with “kie-server” access. Once the login is successful, you can now see the following XML page. KIE server Success XML page Here is a screen recording for your reference: Accessing the KIE server XML page 5. Get the KIE module from jBPM. In Step 2 of the “Using the JBPM server” section, we imported the “IT orders” project. We will need this project in our local system. Click on the gear icon on the top right corner and go to Artifacts and download the JAR and POM files, else you can just configure SSH keys in the same page itself(just like you do with GitHub) and then go to Projects -&gt; MySpace -&gt; IT_Orders -&gt; Settings and copy the SSH link and clone it in your local system. Sometimes, there may be issues with SSH, so there is another way. Go to the hidden “.niogit” folder inside JBPM_HOME or root folder. You can see a “MySpace” folder, inside it there is an “IT_Orders.git”, you can clone this .git file in the same file location using git clone IT_Orders.git. Once it is cloned, open a terminal in the newly created “IT_Orders” folder and run a mvn clean install. Now that we have the required KIE module in our local Maven repository, we can create a KIE container using the same. Note: 1. The “.niogit” folder may be hidden, make sure you can see all the hidden folders so that you can access them. 2. You will have to alternatively jBPM and WildFly and not simultaneously. 3. We need to have the KIE module in our local Maven repository so that KIE server can access it and we can create a container using it. 4. Sometimes you may run into “dashbuilder-webapp-7.56.0.Final”.”org.uberfire.server.locale.GWTLocaleHeaderFilter”: java.lang.OutOfMemoryError: Metaspace, open this file: bin/standalone.conf and look for these properties and increase to 512m/1024m -XX:MetaspaceSize=512M -XX:MaxMetaspaceSize=512m, this is how it looks after changing: Tweaked MetaSpaceSize in bin/standalone.conf 6. Your KIE server is running. You can now goto &lt;a href="http://127.0.0.1:8080/kie-server-7.57.0.Final-ee8/docs/"&gt;http://127.0.0.1:8080/kie-server-7.57.0.Final-ee8/docs/&lt;/a&gt; to see the Swagger docs and access the REST endpoints for KIE server. Create a container by going to the “KIE server and KIE containers section” and executing the “PUT ”, you can now see a 200 Ok response. Example PUT request URL and JSON request body data { "container-id" : "MyProject", "release-id" : { "group-id" : "itorders", "artifact-id" : "itorders", "version" : "1.0.0-SNAPSHOT" } } You need to use the appropriate group-id, artifact-id and version as in the pom.xml inside IT_Orders project that you cloned earlier(In our case, use “itorders” for both group-id and version-id and “1.0.0-SNAPSHOT” for version). IT_Orders pom.xml Your container is now created. You can now execute “GET ” to get information about the KIE server. Here is an example of what the above GET request sends as a response. { "type": "SUCCESS", "msg": "List of created containers", "result": { "kie-containers": { "kie-container": [ { "container-id": "itorders_1.0.0-SNAPSHOT", "release-id": { "group-id": "itorders", "artifact-id": "itorders", "version": "1.0.0-SNAPSHOT" }, "resolved-release-id": { "group-id": "itorders", "artifact-id": "itorders", "version": "1.0.0-SNAPSHOT" }, "status": "STARTED", "scanner": { "status": "DISPOSED", "poll-interval": null }, "config-items": [], "container-alias": "itorders" } ] } } } Refer to the to know more about the endpoints and their uses. You can also know more by just following the Swagger documentation, which is fairly detailed in itself. If you aren’t comfortable with Swagger, feel free to use your own command-line interface or Postman. Make sure you run a “GET /server” to get information about the KIE server. The endpoint for this request is the base URL for the REST API. You needn’t worry about the exact curl commands. As soon as you click on “Execute” for a request, you get the corresponding curl commands as well. If you encounter request errors, review the returned error code messages and adjust your request accordingly. Here is a screenshot for your reference. Getting the corresponding curl commands to run in terminal or Postman 7. Head over to the Process Instances section in the Swagger documentation and execute “GET ” to get the processes which you will be using to create process instances. Copy a process where you want to create a instance. Execute “ POST ” in the beginning of the same section with the copied processId and the containerId to create an instance. The body is a JSON object. You can create multiple instances. 8. Once you successfully create process instances, open WILDFLY_HOME/standalone/configuration/standalone-full.xml as root and add the following system properties to let DashBuilder access the server, and restart the WildFly server. You will now be able to access the dataset inside DashBuilder. The serverTemplates property is specially configured for DashBuilder that makes sure that dropdown against the Remote Server Template field in the Execution server’s Data Set Creation Wizard in DashBuilder is populated. Add system properties to standalone-full.xml You may also need to add the following properties when you are using DashBuilder Runtime: dashbuilder.kieserver.serverTemplate.{SERVER_TEMPLATE}.location dashbuilder.kieserver.serverTemplate.{SERVER_TEMPLATE}.user dashbuilder.kieserver.serverTemplate.{SERVER_TEMPLATE}.password dashbuilder.kieserver.serverTemplate.{SERVER_TEMPLATE}.token The token system property is an alternative, it can be used when the KIE server is configured to use a token instead of user/password. There’s also a system property to make DashBuilder create the queries on KIE Server. If true, then DB creates the query on KIE Server: dashbuilder.kieserver.serverTemplate.{SERVER_TEMPLATE}.replace_query Note: * You will have to restart the WildFly server every time you make any changes to standalone-full.xml for changes to reflect. * Make sure that the serverTemplate.location is the same as the URL you used to access the KIE REST API. There is a high possibility of the kie-server name being wrong. In that case, you might get a 405 Method Not Allowed error while trying to access the data inside DashBuilder with all the correct values. 9. You can now access the Configured dataset inside DashBuilder. Go to the Deployments tab and click on the link against “Context Root”. Log in to DashBuilder using the ApplicationRealm user credentials with “kieserver” access(the same that you need to login to the KIE server) you created in the beginning. You will see the homepage which resembles the screen below. DashBuilder Home page 10. In order to add a dataset, select Datasets from the menu. Alternatively, you can also click on the “Menu” dropdown on the top left corner beside the DashBuilder logo on the navigation bar. You will now see two headings, “DashBuilder” and “Administration”. Click on “Datasets” under Administration. You will see the Dataset Authoring home page with instructions to add datasets, create displayers and new dashboards. Click on the “new data set” hyperlink and repeat the steps 4–7 in the “Using the jBPM server” section in this post to add the dataset and create dashboards. CONCLUSION With the help of this post, you will be able to add and configure data from a KIE execution server to be consumed by your dashboards. Feel free to add your comments regarding where you got stuck so that we can improve and update this guide going further. In the upcoming posts, we will add walkthroughs of the remaining dataset providers, so stay tuned! The post appeared first on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/AcKfROLShQU" height="1" width="1" alt=""/&gt;</content><dc:creator>Manaswini Das</dc:creator><feedburner:origLink>https://blog.kie.org/2021/08/add-data-from-kie-execution-server-for-authoring-dashboards.html</feedburner:origLink></entry><entry><title>Troubleshooting application performance with Red Hat OpenShift metrics, Part 5: Test results</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/yc3mN6Z2wZw/troubleshooting-application-performance-red-hat-openshift-metrics-part-5-test" /><author><name>Pavel Macik</name></author><id>4982d43a-69c7-4f0c-bc78-b3826ca99f4c</id><updated>2021-08-05T07:00:00Z</updated><published>2021-08-05T07:00:00Z</published><summary type="html">&lt;p&gt;This is the final article in a series demonstrating the process of performance testing &lt;a href="https://developers.redhat.com/blog/2019/12/19/introducing-the-service-binding-operator"&gt;Service Binding Operator&lt;/a&gt; for acceptance into the &lt;a href="https://developers.redhat.com/developer-sandbox"&gt;Developer Sandbox for Red Hat OpenShift&lt;/a&gt;. In Part 4, I explained how I gathered performance metrics for the Developer Sandbox team. I also discussed the additional metrics we used to measure the developer experience using Service Binding Operator.&lt;/p&gt; &lt;p&gt;The payoff comes in this final article, where I present the test rounds I undertook as the application developed and how I interpreted the results.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Read the whole series&lt;/strong&gt;:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Part 1: &lt;a href="https://developers.redhat.com/articles/2021/07/08/troubleshooting-application-performance-red-hat-openshift-metrics-part-1"&gt;Performance requirements&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Part 2: &lt;a href="https://developers.redhat.com/articles/2021/07/15/troubleshooting-application-performance-red-hat-openshift-metrics-part-2-test"&gt;The test environment&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Part 3: &lt;a href="https://developers.redhat.com/articles/2021/07/22/troubleshooting-application-performance-red-hat-openshift-metrics-part-3"&gt;Collecting runtime metrics&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Part 4: &lt;a href="https://developers.redhat.com/articles/2021/07/29/troubleshooting-application-performance-red-hat-openshift-metrics-part-4"&gt;Gathering performance metrics&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Part 5: Test rounds and results&lt;/strong&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;Test configuration&lt;/h2&gt; &lt;p&gt;The following sections show the test rounds as they evolved over time. The title of each test round summarizes the test configuration, in the following format:&lt;/p&gt; &lt;pre&gt; "&lt;strong&gt;A&lt;/strong&gt; users, &lt;strong&gt;B&lt;/strong&gt; active, &lt;strong&gt;C&lt;/strong&gt;/&lt;strong&gt;D&lt;/strong&gt; SB, &lt;strong&gt;E&lt;/strong&gt; NS on OCP v &lt;strong&gt;F&lt;/strong&gt;" &lt;/pre&gt; &lt;p&gt;Here is the key for understanding the test configuration from each title:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;strong&gt;A&lt;/strong&gt;: The overall number of simulated (registered) users.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;B&lt;/strong&gt;: The number of active users.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;C&lt;/strong&gt;: The overall number of &lt;code&gt;ServiceBinding&lt;/code&gt; resources created along with the other user workloads (the "With SBR" scenario).&lt;/li&gt; &lt;li&gt;&lt;strong&gt;D&lt;/strong&gt;: The overall number of &lt;code&gt;ServiceBinding&lt;/code&gt; resources created after all of the users were provisioned (the "Without SBR" scenario).&lt;/li&gt; &lt;li&gt;&lt;strong&gt;E&lt;/strong&gt;: The overall number of namespaces created for simulated users.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;F&lt;/strong&gt;: The underlying version of my cluster on Red Hat OpenShift Container Platform.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;As we continually upgraded the tool, we tested successive versions. I will present the test results for Service Binding Operator versions 0.5.0, 0.6.0, 0.7.0, and 0.7.1.&lt;/p&gt; &lt;h2&gt;Performance testing Service Binding Operator 0.5.0&lt;/h2&gt; &lt;p&gt;I started with Service Binding Operator 0.5.0, which was at that time the latest version released by Red Hat.&lt;/p&gt; &lt;h3&gt;Test run 1: With Service Binding resources&lt;/h3&gt; &lt;p&gt;The very first round of the performance evaluation is titled &lt;em&gt;With SBR - 3000 users, 600 active, 600/0 SB, 9000 NS on OCP v4.6.20&lt;/em&gt;. We provisioned the maximum number of users specified in our requirements, which was 3,000. Of these, only every fifth user was active, or 600 overall. This was the default ratio used by the Developer Sandbox testing tool.&lt;/p&gt; &lt;p&gt;In this run, the cluster survived, but the numbers were scary for Service Binding Operator. Memory use went up to a peak of 12 GiB and the CPU usage rose to approximately 3 vCPU. Service Binding Operator's performance was also not good, taking up to approximately 20 minutes to process the last of the 600 &lt;code&gt;ServiceBinding&lt;/code&gt; requests. Figure 1 shows the charts I generated to observe test metrics.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/sbo_v0.5.0_low.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/sbo_v0.5.0_low.png?itok=DP0r0zQw" width="600" height="315" alt="Test results "With SBR - 3000 users, 600 active, 600/0 SB, 9000 NS on OCP v4.6.20." Time to Ready rises drastically and continuously. Memory usage and CPU usage also rise quickly and decline only slightly from their peaks." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1: Test results "With SBR - 3000 users, 600 active, 600/0 SB, 9000 NS on OCP v4.6.20." &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;h3&gt;Test run 2: With Service Binding resources&lt;/h3&gt; &lt;p&gt;After the initial performance test, with only 20% of users active, I increased the ratio to 50%, so there were 1,500 active users out of 3,000 registered. I wanted to see whether memory consumption would rise even more. This test is titled &lt;em&gt;With SBR - 3000 users, 1500 active, 1500/0 SB, 9000 NS on OCP v4.6.20&lt;/em&gt;.&lt;/p&gt; &lt;p&gt;The cluster also survived in this run, but Service Binding Operator consumed an enormous amount of resources. Memory use was still high at 11 GiB, and the CPU usage went over 4.5 vCPU. Service Binding Operator showed even worse performance, as the last of the 1,500 &lt;code&gt;ServiceBinding&lt;/code&gt; requests took more than 30 minutes to finish. Figure 2 shows the results.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/sbo_v0.5.0_high.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/sbo_v0.5.0_high.png?itok=e_Uh_XG8" width="600" height="315" alt="Test results "With SBR - 3000 users, 1500 active, 1500/0 SB, 9000 NS on OCP v4.6.20." Time to Ready still rises high, although not as drastically. Memory usage has a slightly lower peak and stays there, but CPU usage has a higher peak." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 2: Test results "With SBR - 3000 users, 1500 active, 1500/0 SB, 9000 NS on OCP v4.6.20." &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;h3&gt;Test run 3: Without Service Binding resources&lt;/h3&gt; &lt;p&gt;Next, I wanted to see what would happen if 1,500 &lt;code&gt;ServiceBinding&lt;/code&gt; requests were sent all at once after the users were successfully provisioned. This test round is titled &lt;em&gt;Without SBR - 3000 users, 1500 active, 0/1500 SB, 9000 NS on OCP v4.6.20&lt;/em&gt;. Figure 3 shows how the systems reacted.&lt;/p&gt; &lt;figure role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/sbo_v0.5.0_without.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/sbo_v0.5.0_without.png?itok=8vjzxUs2" width="600" height="315" alt="Test results "Without SBR - 3000 users, 1500 active, 0/1500 SB, 9000 NS on OCP v4.6.20." Time to Ready shows sudden, short processing effort. Memory usage is high throughout, even before SBO starts handling bindings. CPU usage suddenly rises when SBO starts." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 3: Test results "Without SBR - 3000 users, 1500 active, 0/1500 SB, 9000 NS on OCP v4.6.20." &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Let's investigate the four interesting phases of this test:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Phase 1: In the initial ~1.5 hours of ramp-up, the tool registered all 3,000 users into the sandbox.&lt;/li&gt; &lt;li&gt;Phase 2: During the next ~5.5 hours, where seemingly nothing happened (from Service Binding Operator's perspective), all of the 1,500 active users were active. They were creating workloads in their respective namespaces. The workloads consisted of the default set plus the backing service and the application to be bound, without the actual &lt;code&gt;ServiceBinding&lt;/code&gt; resource.&lt;/li&gt; &lt;li&gt;Phase 3: During the last ~6 minutes, all of the 1,500 &lt;code&gt;ServiceBinding&lt;/code&gt; resources (for active users) were created and processed by Service Binding Operator.&lt;/li&gt; &lt;li&gt;Phase 4: The final phase shows what Service Binding Operator was doing afterward.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;From our analysis of the results and code, we discovered the reason why Service Binding Operator took lots of memory even when it was supposed to be idle (in Phases 1 and 2): It watched for many resources, just in case, that were not related to binding requests. It then cached all that information in memory. Based on that observation, we decided to &lt;a href="https://github.com/redhat-developer/service-binding-operator/pull/903" target="_blank"&gt;drop the just-in-case watches&lt;/a&gt;. These changes were merged and we released a new version of Service Binding Operator, 0.6.0. Next, we'll look at the results of performance evaluations of this new version.&lt;/p&gt; &lt;h2&gt;Performance testing Service Binding Operator 0.6.0&lt;/h2&gt; &lt;p&gt;In this round, we wanted to see what happened when all of the simulated users were active. Unfortunately, I wasn't able to simulate all 3,000 users as active because the time needed for provisioning them exceeded the lifespan of my temporary OpenShift cluster (about 10 hours). So, I had to stop the provisioning sooner than the full capacity of 3,000 users was reached. That is why the following results have only 2,599 and 2,800 active users, respectively.&lt;/p&gt; &lt;h3&gt;Test run 4: With Service Binding resources&lt;/h3&gt; &lt;p&gt;This run is titled &lt;em&gt;With SBR - 3000 users, 2599 active, 2599/0 SB, 9000 NS on OCP v4.6.20&lt;/em&gt;. We saw an impressive performance improvement with this new version of Service Binding Operator after dropping the just-in-case watches. This was true even when the number of active users along with &lt;code&gt;ServiceBinding&lt;/code&gt; requests almost doubled, as shown in Figure 4.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/sbo_v0.6.0_with.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/sbo_v0.6.0_with.png?itok=XI_Bnivb" width="600" height="315" alt="Test results "With SBR - 3000 users, 2599 active, 2599/0 SB, 9000 NS on OCP v4.6.20." Time to Ready is very even, with a few spikes. Memory usage rises gradually, while CPU usage remains mostly even." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 4: Test results "With SBR - 3000 users, 2599 active, 2599/0 SB, 9000 NS on OCP v4.6.20." &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;Note the following:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Memory usage dropped from a peak of ~11 GiB to a peak of ~80 MiB (approximately 140 times less memory usage).&lt;/li&gt; &lt;li&gt;CPU usage dropped from a peak of ~4.5 vCPU to a peak of ~0.0034 vCPU (approximately 1,323 times less CPU usage).&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Test run 5: Without Service Binding resources&lt;/h3&gt; &lt;p&gt;This run is titled &lt;em&gt;Without SBR - 3000 users, 2800 active, 0/2800 SB, 9000 NS on OCP v4.6.20&lt;/em&gt;. This was the first time I split the Service Binding Operator metrics into different parts, to understand where the most time was spent. It is interesting to see that the time spent on binding was about 0.5 seconds, even when the time from the creation of &lt;code&gt;ServiceBinding&lt;/code&gt; request to the creation of the binding was around 13 minutes in the worst case. This observation revealed that it is not Service Binding Operator that causes the long processing time, but rather something in OpenShift itself—most likely in the API servers processing the incoming &lt;code&gt;ServiceBinding&lt;/code&gt; requests. Keep in mind that all of the 2,800 &lt;code&gt;ServiceBinding&lt;/code&gt; requests were thrown at the cluster's API servers in as short a period of time as possible.&lt;/p&gt; &lt;p&gt;The results in Figure 5 show that the idle Service Binding Operator took only 25 MiB of memory and almost no CPU.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/sbo_v0.6.0_without.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/sbo_v0.6.0_without.png?itok=ZbkdRQ2T" width="600" height="527" alt="Test results "Without SBR - 3000 users, 2800 active, 0/2800 SB, 9000 NS on OCP v4.6.20." All activity starts when SBO begins to process bindings, and rises quickly." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 5: Test results "Without SBR - 3000 users, 2800 active, 0/2800 SB, 9000 NS on OCP v4.6.20." &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;During a couple of attempts, one of the follower nodes in the OpenShift cluster actually crashed. The cause was that the API servers were overloaded with all of the incoming activity of user provisioning, which caused that node to stop responding. Based on that observation, I extended the watched metrics to uncover the bottlenecks, as described in the &lt;a href="https://developers.redhat.com/articles/2021/07/29/troubleshooting-application-performance-red-hat-openshift-metrics-part-4"&gt;previous article in this series&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Performance testing Service Binding Operator 0.7.0&lt;/h2&gt; &lt;p&gt;Another concurrent optimization of Service Binding Operator, &lt;a href="https://github.com/redhat-developer/service-binding-operator/pull/919" target="_blank"&gt;reconcile loop refactoring&lt;/a&gt;, greatly improved the code and allowed the Service Binding Operator core to be used as a library—a feature that had been requested by various teams (such as the &lt;a href="products/odo/overview"&gt;odo&lt;/a&gt; CLI tool team). We released a new version of Service Binding Operator numbered 0.7.0, and we needed to ensure that the optimization didn't degrade performance.&lt;/p&gt; &lt;p&gt;At the same time, a couple of test parameters changed significantly:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Based on the crashes caused when the API servers and monitoring pods were overloaded with 3,000 active users, the Developer Sandbox team decided to lower the capacity of a single cluster for production sandbox instances from 3,000 to 2,000.&lt;/li&gt; &lt;li&gt;For the same reasons, the number of namespaces available for each user was decreased from three to two.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;I changed my tests to match these relaxed requirements. Also, the version of OpenShift underlying the Developer Sandbox was updated to version 4.7.x, so I updated my OpenShift Container Platform version to match.&lt;/p&gt; &lt;p&gt;Let's examine the test runs under these new conditions.&lt;/p&gt; &lt;h3&gt;Test run 6: With Service binding resources&lt;/h3&gt; &lt;p&gt;Figure 6 shows our first and only run on Service Binding Operator 0.7.0. Performance was stable throughout the run, and reasonably good. This test run was titled &lt;em&gt;With SBR - 2000 users, 2000 active, 2000/0 SB, 4000 NS on OCP v4.7.4&lt;/em&gt;.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/sbo_v0.7.0.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/sbo_v0.7.0.png?itok=9CgFxBSe" width="600" height="527" alt="Test results "With SBR - 2000 users, 2000 active, 2000/0 SB, 4000 NS on OCP v4.7.4." Activity was fairly stable throughout the test." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 6: Test results "With SBR - 2000 users, 2000 active, 2000/0 SB, 4000 NS on OCP v4.7.4." &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;As mentioned in the &lt;a href="https://developers.redhat.com/articles/2021/07/08/troubleshooting-application-performance-red-hat-openshift-metrics-part-1"&gt;first article in this series&lt;/a&gt;, one requirement for running in the Developer Sandbox was for Service Binding Operator to work with the &lt;a href="https://github.com/redhat-developer/app-services-operator"&gt;Red Hat OpenShift Application Services&lt;/a&gt; Operator. Soon after Service Binding Operator 0.7.0 was released, a regression affecting the Red Hat OpenShift Application Services Operator was &lt;a href="https://github.com/redhat-developer/service-binding-operator/issues/945" target="_blank"&gt;found&lt;/a&gt;. The problem was quickly &lt;a href="https://github.com/redhat-developer/service-binding-operator/pull/949" target="_blank"&gt;fixed&lt;/a&gt; and Service Binding Operator 0.7.1 was released with the bug fix. That happened quite fast, so by the time I planned to test the new scenario, Service Binding Operator 0.7.1 was already on its way. It didn't make sense to test the "Without SBR" scenario with Service Binding Operator 0.7.0, so I skipped right to the newest version.&lt;/p&gt; &lt;h2&gt;Performance testing Service Binding Operator 0.7.1&lt;/h2&gt; &lt;p&gt;We finished our exploration of Service Binding Operator's performance with one test run on the bug-fix version.&lt;/p&gt; &lt;h3&gt;Test run 7: Without Service binding resources&lt;/h3&gt; &lt;p&gt;This test run was titled &lt;em&gt;Without SBR - 2000 users, 2000 active, 0/2000 SB, 4000 NS on OCP v4.7.6.&lt;/em&gt; Our intention was to verify that the performance held even with the recent bug-fix release—and it did, as shown in Figure 7.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/sbo_v0.7.1.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/sbo_v0.7.1.png?itok=lRp1rQB9" width="600" height="527" alt="Test results "Without SBR - 2000 users, 2000 active, 0/2000 SB, 4000 NS on OCP v4.7.6." Performance rose rapidly when SBO processed bindings, but did not rise dangerously high." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 7: Test results "Without SBR - 2000 users, 2000 active, 0/2000 SB, 4000 NS on OCP v4.7.6." &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;h2&gt;Conclusion: Performance analysis and results&lt;/h2&gt; &lt;p&gt;Ultimately, the version of Service Binding Operator that was accepted and installed in the production deployment of Developer Sandbox was 0.7.0, which we later updated with the bug-fix release of 0.7.1. That version was used at the Red Hat Summit in the &lt;a href="https://developers.redhat.com/developer-sandbox/activities/connecting-to-your-managed-kafka-instance" target="_blank"&gt;Connecting to your Managed Kafka instance from the Developer Sandbox for Red Hat OpenShift&lt;/a&gt; demo and workshop. It ran smoothly without any problems. The Service Binding Operator is currently available to any developer playing with the Developer Sandbox.&lt;/p&gt; &lt;p&gt;During the evaluation, we improved Service Binding Operator's performance dramatically:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Memory usage dropped from a peak of ~11 GiB to a peak of ~80 MiB (approximately 140 times less memory usage).&lt;/li&gt; &lt;li&gt;CPU usage dropped from a peak of ~4.5 vCPU to a peak of ~0.0034 vCPU (approximately 1,323 times less CPU usage).&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;In addition, we demonstrated a problem with the underlying OpenShift cluster, which could crash for internal reasons when fully loaded with active users. Our testing led the Developer Sandbox team to decrease requirements from 3,000 to 2,000 users and to decrease the number of namespaces available for each user from three to two to ensure the stability of the sandbox. Both the improvements to Service Binding Operator and the policy decisions by the Developer Sandbox team demonstrate the value of running performance tests and collecting matrics on Red Hat OpenShift.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/08/05/troubleshooting-application-performance-red-hat-openshift-metrics-part-5-test" title="Troubleshooting application performance with Red Hat OpenShift metrics, Part 5: Test results"&gt;Troubleshooting application performance with Red Hat OpenShift metrics, Part 5: Test results&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/yc3mN6Z2wZw" height="1" width="1" alt=""/&gt;</summary><dc:creator>Pavel Macik</dc:creator><dc:date>2021-08-05T07:00:00Z</dc:date><feedburner:origLink>https://developers.redhat.com/articles/2021/08/05/troubleshooting-application-performance-red-hat-openshift-metrics-part-5-test</feedburner:origLink></entry><entry><title type="html">WildFly 24.0.1 S2I images have been released on quay.io</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/B1gVTeNtK2Y/" /><author><name>Ken Wills</name></author><id>https://wildfly.org//news/2021/08/05/WildFly-s2i-2401-Released/</id><updated>2021-08-05T00:00:00Z</updated><content type="html">WILDFLY 24.0.1 S2I DOCKER IMAGES The WildFly S2I (Source-to-Image) builder and runtime Docker images for WildFly 24.0.1, have been released on . For complete documentation on how to use these images using S2I, OpenShift and Docker, refer to the WildFly S2I . HELM CHART FOR WILDFLY The has been updated to use the WildFly S2I 24.0.1 images. The is a good place to start using the Helm Chart with the WildFly S2I images. Enjoy!&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/B1gVTeNtK2Y" height="1" width="1" alt=""/&gt;</content><dc:creator>Ken Wills</dc:creator><feedburner:origLink>https://wildfly.org//news/2021/08/05/WildFly-s2i-2401-Released/</feedburner:origLink></entry><entry><title type="html">DevConf.US 2021 - Designing your best architecture diagrams workshop</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/5c5h8SaqLp8/devconfus-2021-designing-your-best-architecture-diagrams-workshop.html" /><author><name>Eric D. Schabell</name></author><id>http://feedproxy.google.com/~r/schabell/jboss/~3/LMdo9vWm8Ds/devconfus-2021-designing-your-best-architecture-diagrams-workshop.html</id><updated>2021-08-04T14:00:00Z</updated><content type="html">ended their call for papers this last month and has announced acceptance for sessions to be hosted on September 2-3.  It's the 4th annual, free, Red Hat sponsored technology conference for community project and professional contributors to Free and Open Source technologies coming to a web browser near you! There is no admission or ticket charge for DevConf.US events. However, you are . Talks, presentations and workshops will all be in English. I had submitted a few talks and workshops and here are my acceptances that arrived this week. Designing your best architecture diagrams (workshop) Diagraming is one of the most important communication tools for sharing your project and architectural ideas to your colleagues and teams. In this workshop attendees are walking step-by-step through using an open source tool we host online for designing architecture diagrams like an expert. Attendees work through the following: * open and explore the tooling in your favourite web browser * explore the provided asset libraries for drag-and-drop designing * learn about the three types of diagrams that make up a good design * create your first simple logical diagram * create your first simple schematic diagram * create a detailed diagram * how to export diagrams and elements from a diagram * design tips and tricks Each of the individual labs in this workshop are stand alone, allowing the attendee to focus on anything of interest without having to work through the previous labs. If you're looking to become more proficient in sharing your ideas, architectures, and projects visually to wider audiences you can't underestimate the value of a good diagram. Join us to learn the tips and tricks that make a good diagram such a good communication vehicle and how our tooling eases your design tasks.  The workshop is fully implemented and tested with designers and architects around the world and fine tuned to the beginning designer. Workshop is  for your previewing pleasure. The schedule has yet to be posted, so keep an eye on the site for exact times if you'd like to attend. Hope to see you there!&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/5c5h8SaqLp8" height="1" width="1" alt=""/&gt;</content><dc:creator>Eric D. Schabell</dc:creator><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/LMdo9vWm8Ds/devconfus-2021-designing-your-best-architecture-diagrams-workshop.html</feedburner:origLink></entry><entry><title>Managing stateful applications with Kubernetes Operators in Golang</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/o1kPvgHNpS4/managing-stateful-applications-kubernetes-operators-golang" /><author><name>Priyanka Jiandani</name></author><id>a090a17f-26ad-49fb-b2e0-ee1c6d9092c8</id><updated>2021-08-04T07:00:00Z</updated><published>2021-08-04T07:00:00Z</published><summary type="html">&lt;p&gt;You can use &lt;a href="https://developers.redhat.com/topics/kubernetes/operators"&gt;Kubernetes Operators&lt;/a&gt; to set up automatic resource management for services in your applications. In a &lt;a href="https://developers.redhat.com/blog/2020/12/16/create-a-kubernetes-operator-in-golang-to-automatically-manage-a-simple-stateful-application"&gt;previous article&lt;/a&gt;, I described this pattern and how to create an operator in the &lt;a href="https://developers.redhat.com/search?t=go"&gt;Go&lt;/a&gt; language. In this article, we will continue to explore the pattern, this time by creating a Kubernetes Operator in Go to keep a WordPress site up to date. I recommend reading or reviewing the earlier article before starting this one.&lt;/p&gt; &lt;h2&gt;Example prerequisites&lt;/h2&gt; &lt;p&gt;I use the following tools in this article's example:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Golang v1.15+&lt;/li&gt; &lt;li&gt;The &lt;a href="https://docs.openshift.com/container-platform/4.7/operators/operator_sdk/osdk-installing-cli.html"&gt;operator-sdk&lt;/a&gt; command-line interface, version 1 or higher&lt;/li&gt; &lt;li&gt;&lt;a href="https://minikube.sigs.k8s.io/docs/start/"&gt;minikube&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://kubernetes.io/docs/tasks/tools/"&gt;kubectl&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;In addition, set this environment variable in your terminal:&lt;/p&gt; &lt;pre&gt; $ export GO111MODULE="on"&lt;/pre&gt; &lt;p&gt;You can see the source code for this article on my &lt;a href="https://github.com/priyanka19-98/wordpress-operator-latest"&gt;GitHub repository&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Set up the environment&lt;/h2&gt; &lt;p&gt;Before coding our automation, we need to set up the environment.&lt;/p&gt; &lt;p&gt;Enter the following command to generate &lt;a href="https://github.com/priyanka19-98/wordpress-operator-latest/commit/3beeff0758bf500b14a68e8e8e7a8d1bf90abb93"&gt;boilerplate code&lt;/a&gt; that accomplishes much of the setup:&lt;/p&gt; &lt;pre&gt; $ operator-sdk init --domain example.com --repo github.com/&lt;git user name&gt;/wordpress-operator &lt;/pre&gt; &lt;h3&gt;Creating the API and controller&lt;/h3&gt; &lt;p&gt;Enter the following to set up the environment for WordPress:&lt;/p&gt; &lt;pre&gt; $ operator-sdk create api --group wordpress --version v1 --kind Wordpress --resource --controller &lt;/pre&gt; &lt;p&gt;The command creates the following files:&lt;/p&gt; &lt;pre&gt; api/v1/wordpress_types.go controllers/wordpress_controller.go&lt;/pre&gt; &lt;h3&gt;Defining the API&lt;/h3&gt; &lt;p&gt;You can make changes to &lt;code&gt;api/v1/wordpress_types.go&lt;/code&gt; to include the attributes that you would like in the &lt;code&gt;WordpressSpec&lt;/code&gt; struct and &lt;code&gt;WordpressStatus&lt;/code&gt; status.&lt;/p&gt; &lt;p&gt;For the sake of simplicity, we will set only one requirement. It places a root password for database access in the &lt;code&gt;WordpressSpec&lt;/code&gt; struct:&lt;/p&gt; &lt;pre&gt; apiVersion: wordpress.example.com/v1 kind: Wordpress metadata: name: mysite spec: sqlRootPassword: plaintextpassword&lt;/pre&gt; &lt;p&gt;After you make the change in &lt;code&gt;api/v1/wordpress_types.go&lt;/code&gt;, run the following commands to ensure that the changes are reflected in the. custom resource definitions (CRDs) in the config directory:&lt;/p&gt; &lt;pre&gt; $ make generate $ make manifests &lt;/pre&gt; &lt;h2&gt;Implement the controller&lt;/h2&gt; &lt;p&gt;Now we can enter the Go code of the example to configure our controller. The WordPress controller struct is named &lt;code&gt;WordpressReconciler&lt;/code&gt; in the current &lt;code&gt;operator-sdk&lt;/code&gt;. In earlier versions, it was named &lt;code&gt;ReconcileWordpress&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;Watching resources&lt;/h3&gt; &lt;p&gt;The boiler-plate code generated automatically creates a watch for the primary resource in the &lt;code&gt;controllers/wordpress_controller.go&lt;/code&gt; file, in the &lt;code&gt;SetupWithmanager&lt;/code&gt; function:&lt;/p&gt; &lt;pre&gt; For(&amp;v1.Wordpress{})&lt;/pre&gt; &lt;p&gt;The preceding line is equivalent to the following code in previous versions of the &lt;code&gt;operator-sdk&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; Watch(&amp;source.Kind{Type: &amp;v1.Wordpress{}}, &amp;handler.EnqueueRequestForObject{})&lt;/pre&gt; &lt;p&gt;The additional resources we watch are the service, the deployment, and the persistent volume claim (PVC):&lt;/p&gt; &lt;pre&gt; Owns(&amp;appsv1.Deployment{}). Owns(&amp;corev1.Service{}). Owns(&amp;corev1.PersistentVolumeClaim{})&lt;/pre&gt; &lt;p&gt;The preceding code is equivalent to the following code in previous versions of the &lt;code&gt;operator-sdk&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; Watch(&amp;source.Kind{Type: &amp;appsv1.Deployment{}}, &amp;handler.EnqueueRequestForOwner{ IsController: True, OwnerType: &amp;v1.Wordpress{}, }) Watch(&amp;source.Kind{Type: &amp;corev1.Service{}}, &amp;handler.EnqueueRequestForOwner{ IsController: true, OwnerType: &amp;v1.Wordpress{}, }) Watch(&amp;source.Kind{Type: &amp;corev1.PersistentVolumeClaim{}}, &amp;handler.EnqueueRequestForOwner{ IsController: true, OwnerType: &amp;v1.Wordpress{}, })&lt;/pre&gt; &lt;p&gt;To sum up, all the watches in the application can be written as:&lt;/p&gt; &lt;pre&gt; For(&amp;v1.Wordpress{}). Owns(&amp;appsv1.Deployment{}). Owns(&amp;corev1.Service{}). Owns(&amp;corev1.PersistentVolumeClaim{}). Complete(r)&lt;/pre&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: To learn more about establishing watches in the &lt;code&gt;operator-sdk&lt;/code&gt;, refer to &lt;a href="https://pkg.go.dev/sigs.k8s.io/controller-runtime/pkg/builder#example-Builder"&gt;Builder docs&lt;/a&gt; and &lt;a href="https://pkg.go.dev/sigs.k8s.io/controller-runtime/pkg/controller"&gt;Controller docs&lt;/a&gt;.&lt;/p&gt; &lt;h3&gt;The reconcile loop&lt;/h3&gt; &lt;p&gt;I introduced the reconcile logic in my previous article. The new version of the &lt;code&gt;operator-sdk&lt;/code&gt; adds a few enhancements. It defines a few role-based access control (RBAC) rules by default:&lt;/p&gt; &lt;pre&gt; //+kubebuilder:rbac:groups=wordpress.example.com,resources=wordpresses,verbs=get;list;watch;create;update;patch;delete //+kubebuilder:rbac:groups=wordpress.example.com,resources=wordpresses/status,verbs=get;update;patch //+kubebuilder:rbac:groups=wordpress.example.com,resources=wordpresses/finalizers,verbs=update &lt;/pre&gt; &lt;p&gt;These are generated in the configuration directory when you run the &lt;code&gt;make manifests&lt;/code&gt; command.&lt;/p&gt; &lt;h3&gt;Logging&lt;/h3&gt; &lt;p&gt;The current &lt;code&gt;operator-sdk&lt;/code&gt; already defines a logger in the &lt;code&gt;WordpressReconciler&lt;/code&gt; struct. As a result, you don’t need to explicitly define your own logger.&lt;/p&gt; &lt;h3&gt;Adding the WordPress controller to the manager&lt;/h3&gt; &lt;p&gt;The current &lt;code&gt;operator-sdk&lt;/code&gt; adds the controller in &lt;code&gt;main.go&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; if err = (&amp;controllers.WordpressReconciler{ Client: mgr.GetClient(), Log: ctrl.Log.Withname(controllers”).Withname(“wordpress”), Scheme: mgr.GetScheme(), }).SetupWithManager(mgr); err!=nil{ // log error message os.Exit(1) } &lt;/pre&gt; &lt;p&gt;Note that this code is equivalent to the following code in previous versions of the &lt;code&gt;operator-sdk&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; if err := controllers.AddToManager(mgr); err != nil { log.Error(err, "") os.Exit(1) } &lt;/pre&gt; &lt;h2&gt;Run the Kubernetes Operator&lt;/h2&gt; &lt;p&gt;You need a Kubernetes cluster for this part of the example. Enter the following command :&lt;/p&gt; &lt;pre&gt; $ make install run &lt;/pre&gt; &lt;p&gt;Open another terminal window and apply the custom resource for WordPress:&lt;/p&gt; &lt;pre&gt; $ kubectl create -f config/samples/wordpress_v1_wordpress.yaml &lt;/pre&gt; &lt;p&gt;Your &lt;code&gt;config/samples/wordpress_v1_wordpress.yaml&lt;/code&gt; must look something like this:&lt;/p&gt; &lt;pre&gt; apiVersion: wordpress.example.com/v1 kind: Wordpress metadata: name: mysite spec: sqlrootpassword: "abc" &lt;/pre&gt; &lt;p&gt;Output from &lt;code&gt;make install run&lt;/code&gt; should be similar to the following:&lt;/p&gt; &lt;pre&gt; /home/pjiandan/go/src/wordpress-operator/bin/controller-gen "crd:trivialVersions=true,preserveUnknownFields=false" rbac:roleName=manager-role webhook paths="./..." output:crd:artifacts:config=config/crd/bases /home/pjiandan/go/src/wordpress-operator/bin/kustomize build config/crd | kubectl apply -f - customresourcedefinition.apiextensions.k8s.io/wordpresses.wordpress.example.com created /home/pjiandan/go/src/wordpress-operator/bin/controller-gen "crd:trivialVersions=true,preserveUnknownFields=false" rbac:roleName=manager-role webhook paths="./..." output:crd:artifacts:config=config/crd/bases /home/pjiandan/go/src/wordpress-operator/bin/controller-gen object:headerFile="hack/boilerplate.go.txt" paths="./..." go fmt ./... go vet ./... go run ./main.go 2021-07-05T14:15:59.495+0530 INFO controller-runtime.metrics metrics server is starting to listen {"addr": ":8080"} 2021-07-05T14:15:59.496+0530 INFO setup starting manager 2021-07-05T14:15:59.497+0530 INFO controller-runtime.manager starting metrics server {"path": "/metrics"} 2021-07-05T14:15:59.497+0530 INFO controller-runtime.manager.controller.wordpress Starting EventSource {"reconciler group": "wordpress.example.com", "reconciler kind": "Wordpress", "source": "kind source: /, Kind="} 2021-07-05T14:15:59.598+0530 INFO controller-runtime.manager.controller.wordpress Starting EventSource {"reconciler group": "wordpress.example.com", "reconciler kind": "Wordpress", "source": "kind source: /, Kind="} 2021-07-05T14:15:59.698+0530 INFO controller-runtime.manager.controller.wordpress Starting EventSource {"reconciler group": "wordpress.example.com", "reconciler kind": "Wordpress", "source": "kind source: /, Kind="} 2021-07-05T14:15:59.799+0530 INFO controller-runtime.manager.controller.wordpress Starting EventSource {"reconciler group": "wordpress.example.com", "reconciler kind": "Wordpress", "source": "kind source: /, Kind="} 2021-07-05T14:15:59.900+0530 INFO controller-runtime.manager.controller.wordpress Starting Controller {"reconciler group": "wordpress.example.com", "reconciler kind": "Wordpress"} 2021-07-05T14:15:59.900+0530 INFO controller-runtime.manager.controller.wordpress Starting workers {"reconciler group": "wordpress.example.com", "reconciler kind": "Wordpress", "worker count": 1} 2021-07-05T14:15:59.900+0530 INFO controllers.Wordpress Reconciling Wordpress 2021-07-05T14:15:59.900+0530 INFO controllers.Wordpress Creating a new PVC {"PVC.Namespace": "default", "PVC.Name": "mysql-pv-claim"} 2021-07-05T14:15:59.947+0530 INFO controllers.Wordpress Creating a new Deployment {"Deployment.Namespace": "default", "Deployment.Name": "wordpress-mysql"} 2021-07-05T14:15:59.969+0530 INFO controllers.Wordpress Creating a new Service {"Service.Namespace": "default", "Service.Name": "wordpress-mysql"} 2021-07-05T14:15:59.977+0530 INFO controllers.Wordpress MySQL isn't running, waiting for 5s 2021-07-05T14:15:59.978+0530 INFO controllers.Wordpress Reconciling Wordpress 2021-07-05T14:15:59.978+0530 INFO controllers.Wordpress MySQL isn't running, waiting for 5s 2021-07-05T14:15:59.998+0530 INFO controllers.Wordpress Reconciling Wordpress 2021-07-05T14:15:59.998+0530 INFO controllers.Wordpress MySQL isn't running, waiting for 5s 2021-07-05T14:16:00.044+0530 INFO controllers.Wordpress Reconciling Wordpress 2021-07-05T14:16:00.044+0530 INFO controllers.Wordpress MySQL isn't running, waiting for 5s 2021-07-05T14:16:00.058+0530 INFO controllers.Wordpress Reconciling Wordpress 2021-07-05T14:16:00.059+0530 INFO controllers.Wordpress MySQL isn't running, waiting for 5s 2021-07-05T14:17:09.986+0530 INFO controllers.Wordpress Reconciling Wordpress 2021-07-05T14:17:09.987+0530 INFO controllers.Wordpress MySQL isn't running, waiting for 5s 2021-07-05T14:17:24.988+0530 INFO controllers.Wordpress Reconciling Wordpress 2021-07-05T14:17:24.988+0530 INFO controllers.Wordpress MySQL isn't running, waiting for 5s 2021-07-05T14:18:09.993+0530 INFO controllers.Wordpress Reconciling Wordpress 2021-07-05T14:18:09.993+0530 INFO controllers.Wordpress MySQL isn't running, waiting for 5s 2021-07-05T14:18:14.993+0530 INFO controllers.Wordpress Reconciling Wordpress 2021-07-05T14:18:14.994+0530 INFO controllers.Wordpress MySQL isn't running, waiting for 5s 2021-07-05T14:19:10.278+0530 INFO controllers.Wordpress Reconciling Wordpress 2021-07-05T14:19:10.278+0530 INFO controllers.Wordpress Creating a new PVC {"PVC.Namespace": "default", "PVC.Name": "wp-pv-claim"} 2021-07-05T14:19:10.292+0530 INFO controllers.Wordpress Creating a new Deployment {"Deployment.Namespace": "default", "Deployment.Name": "wordpress"} 2021-07-05T14:19:10.309+0530 INFO controllers.Wordpress Creating a new Service {"Service.Namespace": "default", "Service.Name": "wordpress"} 2021-07-05T14:19:10.341+0530 INFO controllers.Wordpress Reconciling Wordpress 2021-07-05T14:19:10.355+0530 INFO controllers.Wordpress Reconciling Wordpress 2021-07-05T14:19:10.361+0530 INFO controllers.Wordpress Reconciling Wordpress 2021-07-05T14:19:10.371+0530 INFO controllers.Wordpress Reconciling Wordpress 2021-07-05T14:19:15.001+0530 INFO controllers.Wordpress Reconciling Wordpress &lt;/pre&gt; &lt;p&gt;From the second terminal window, check for the resources created as follows:&lt;/p&gt; &lt;pre&gt; [pjiandan@localhost wordpress-operator]$ kubectl get all NAME READY STATUS RESTARTS AGE pod/wordpress-7446b985d9-vc7w2 1/1 Running 0 128m pod/wordpress-mysql-5cd8987844-4p6jp 1/1 Running 0 128m NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/kubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 3h58m service/wordpress NodePort 10.110.12.200 &lt;none&gt; 80:32324/TCP 128m service/wordpress-mysql ClusterIP None &lt;none&gt; 3306/TCP 128m NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/wordpress 1/1 1 1 128m deployment.apps/wordpress-mysql 1/1 1 1 128m NAME DESIRED CURRENT READY AGE replicaset.apps/wordpress-7446b985d9 1 1 1 128m replicaset.apps/wordpress-mysql-5cd8987844 1 1 1 128m &lt;/pre&gt; &lt;p&gt;Next, run the following command to return the IP address for the WordPress service:&lt;/p&gt; &lt;pre&gt; [pjiandan@localhost wordpress-operator]$ minikube service wordpress --url http://192.168.99.143:32324 &lt;/pre&gt; &lt;h2&gt;Verify that WordPress is running&lt;/h2&gt; &lt;p&gt;Open the URL in your browser to verify that WordPress is running, as shown in Figure 1.&lt;/p&gt; &lt;figure role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/go_wp.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/go_wp.png?itok=bwV0o7ML" width="359" height="538" alt="A running instance of WordPress shows that the Operator was successful." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;span class="field field--name-field-creator field--type-string field--label-inline field__items"&gt; &lt;span class="field__label"&gt;Creator&lt;/span&gt; &lt;span class="rhd-media-creator field__item"&gt; &lt;/span&gt; &lt;/span&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1: A running instance of WordPress. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;Visit my &lt;a href="https://github.com/priyanka19-98/wordpress-operator-latest"&gt;GitHub repository&lt;/a&gt; to see all of the code used in this example.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/08/04/managing-stateful-applications-kubernetes-operators-golang" title="Managing stateful applications with Kubernetes Operators in Golang"&gt;Managing stateful applications with Kubernetes Operators in Golang&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/o1kPvgHNpS4" height="1" width="1" alt=""/&gt;</summary><dc:creator>Priyanka Jiandani</dc:creator><dc:date>2021-08-04T07:00:00Z</dc:date><feedburner:origLink>https://developers.redhat.com/articles/2021/08/04/managing-stateful-applications-kubernetes-operators-golang</feedburner:origLink></entry><entry><title type="html">Quarkus 2.1.1.Final released - Maintenance release</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/cRyuPltb2bg/" /><author><name /></author><id>https://quarkus.io/blog/quarkus-2-1-1-final-released/</id><updated>2021-08-04T00:00:00Z</updated><content type="html">We just released Quarkus 2.1.1.Final, our first maintenance release on top of 2.1. It is a safe upgrade for anyone already using 2.1.0.Final. If you are not using 2.1 already, please refer to the 2.1 migration guide. Full changelog You can get the full changelog of 2.1.1.Final on GitHub. Come...&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/cRyuPltb2bg" height="1" width="1" alt=""/&gt;</content><dc:creator /><feedburner:origLink>https://quarkus.io/blog/quarkus-2-1-1-final-released/</feedburner:origLink></entry></feed>
